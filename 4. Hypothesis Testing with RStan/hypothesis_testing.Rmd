---
title: "Байесовская проверка гипотез с помощью RStan"
author: "Марина Дубова"
output: html_notebook
---

```{r}
library(rstan)
library(ggmcmc)
library(bridgesampling)
```

```{r}
set.seed(100)

N <- 50
true_mu <- 90
# true_sigma <- 125
test_scores <- rnorm(N, true_mu, 15)
data_1 <- list(N = length(test_scores), X = test_scores)
```

Нулевая гипотеза: результаты теста нормально распределены со средним 100

```{r}
H0 <-
'
data {
  int<lower = 0> N;  // размер выборки
  vector[N] X; // вектор наблюдений
}

parameters {
  real<lower = 0> sigma; // оцениваемый параметр: стандартное отклонение нормального распределения
}

model {
  sigma ~ cauchy(0, 10); // априорное распределение стандартного отклонения
  X ~ normal(100, sigma); // функция правдоподобия
}
'
```

Альтернативная гипотеза: результаты теста нормально распределены, при этом среднее может не равняться 100 (и быть где угодно в интервале возможных значений)

```{r}
H1 <-
'
data {
  int<lower = 0> N;  // размер выборки
  vector[N] X; // вектор наблюдений
}

parameters {
  real<lower = 0, upper = 200> mu; // оцениваемый параметр: среднее нормального распределения
  real<lower = 0> sigma; // оцениваемый параметр: стандартное отклонение нормального распределения
}

model {
  mu ~ uniform(0, 200); // априорное распределение среднего
  sigma ~ cauchy(0, 10); // априорное распределение стандартного отклонения
  X ~ normal(mu, sigma); // функция правдоподобия
}
'
```

```{r}
# компилируем модели, соответствующие двум гипотезам
stanmodelH0 <- stan_model(model_code = H0, model_name = 'H0') 
stanmodelH1 <- stan_model(model_code = H1, model_name = 'H1')

# сэмплируем "предсказания" каждой из гипотез (моделей), нужно сгенерировать очень много 
fit_H0 <- sampling(stanmodelH0, data_1, iter = 20000, warmup = 1000)
fit_H1 <- sampling(stanmodelH1, data_1, iter = 20000, warmup = 1000)
```

```{r}
# считаем логарифм правдоподобия имеющихся данных для каждой из гипотез (моделей)
H0_res <- bridge_sampler(fit_H0, silent = TRUE)
H1_res <- bridge_sampler(fit_H1, silent = TRUE)
print(H0_res)
print(H1_res)
```

```{r}
error_measures(H0_res)$percentage
error_measures(H1_res)$percentage
```

```{r}
# считаем Байес-фактор (в пользу альтернативной гипотезы)
BF10 <- bf(H1_res, H0_res)
print(BF10)
```

А если данные сгенерированы в соответствии с нулевой гипотезой?

Можно получить "подтверждение" нулевой гипотезы :)

```{r}
set.seed(100)

N <- 50
true_mu <- 100

test_scores <- rnorm(N, true_mu, 15)
data_2 <- list(N = length(test_scores), X = test_scores)
```


```{r}
fit_H0 <- sampling(stanmodelH0, data_2, iter = 20000, warmup = 1000)
fit_H1 <- sampling(stanmodelH1, data_2, iter = 20000, warmup = 1000)
```

```{r}
# считаем логарифм правдоподобия имеющихся данных для каждой из гипотез (моделей)
H0_res <- bridge_sampler(fit_H0, silent = TRUE)
H1_res <- bridge_sampler(fit_H1, silent = TRUE)
print(H0_res)
print(H1_res)
```

```{r}
error_measures(H0_res)$percentage
error_measures(H1_res)$percentage
```

```{r}
# считаем Байес-фактор (в пользу альтернативной гипотезы)
BF10 <- bf(H1_res, H0_res)
print(BF10)

# считаем Байес-фактор (в пользу нулевой гипотезы)
BF01 <- bf(H0_res, H1_res)
print(BF01)
```